"""
An√°lise Hist√≥rica MELHORADA - BTC/BRL
Com tratamento robusto de API e m√∫ltiplas formas de detectar quedas
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict
import time

class ImprovedBacktestAnalyzer:
    def __init__(self):
        self.base_url = "https://api.binance.com"
        self.symbol = "BTCBRL"
        
    def get_historical_data(self, days: int = 180, retries: int = 3) -> pd.DataFrame:
        """Busca dados hist√≥ricos com retry e headers apropriados"""
        print(f"üì• Baixando {days} dias de dados hist√≥ricos...")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        for attempt in range(retries):
            try:
                url = f"{self.base_url}/api/v3/klines"
                end_time = int(datetime.now().timestamp() * 1000)
                start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
                
                params = {
                    'symbol': self.symbol,
                    'interval': '1d',
                    'startTime': start_time,
                    'endTime': end_time,
                    'limit': 1000
                }
                
                response = requests.get(url, params=params, headers=headers, timeout=15)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if len(data) == 0:
                        print(f"‚ö†Ô∏è  Nenhum dado retornado")
                        return None
                    
                    df = pd.DataFrame(data, columns=[
                        'timestamp', 'open', 'high', 'low', 'close', 'volume',
                        'close_time', 'quote_volume', 'trades', 'taker_buy_base',
                        'taker_buy_quote', 'ignore'
                    ])
                    
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    df['date'] = df['timestamp'].dt.date
                    for col in ['open', 'high', 'low', 'close', 'volume']:
                        df[col] = df[col].astype(float)
                    
                    print(f"‚úÖ {len(df)} dias baixados\n")
                    return df[['date', 'timestamp', 'open', 'high', 'low', 'close', 'volume']]
                
                else:
                    print(f"‚ö†Ô∏è  Tentativa {attempt + 1}/{retries} - Status: {response.status_code}")
                    if attempt < retries - 1:
                        time.sleep(2 ** attempt)  # Exponential backoff
                        
            except Exception as e:
                print(f"‚ö†Ô∏è  Tentativa {attempt + 1}/{retries} - Erro: {e}")
                if attempt < retries - 1:
                    time.sleep(2 ** attempt)
        
        print("‚ùå N√£o foi poss√≠vel baixar dados da API ap√≥s v√°rias tentativas")
        print("üí° DICA: Tente novamente em alguns minutos ou verifique sua conex√£o")
        return None
    
    def find_drops_advanced(self, df: pd.DataFrame, min_drop: float = 5.0) -> pd.DataFrame:
        """
        Detecta quedas usando M√öLTIPLOS m√©todos:
        1. Close-to-close (dia anterior para dia seguinte)
        2. Peak-to-valley (de m√°xima para m√≠nima em qualquer per√≠odo)
        3. Intraday (alta para baixa no mesmo dia)
        """
        
        # M√©todo 1: Close to close (original)
        df['change_close'] = df['close'].pct_change() * 100
        drops_close = df[df['change_close'] <= -min_drop].copy()
        drops_close['tipo'] = 'Close-to-Close'
        
        # M√©todo 2: Drawdown (de pico recente para vale)
        # Calcula a m√°xima dos √∫ltimos 30 dias
        df['rolling_max'] = df['high'].rolling(window=30, min_periods=1).max()
        df['drawdown'] = ((df['low'] - df['rolling_max']) / df['rolling_max']) * 100
        drops_drawdown = df[df['drawdown'] <= -min_drop].copy()
        drops_drawdown['tipo'] = 'Peak-to-Valley'
        drops_drawdown['change_close'] = drops_drawdown['drawdown']
        
        # M√©todo 3: Intraday (alta para baixa no mesmo dia)
        df['change_intraday'] = ((df['low'] - df['high']) / df['high']) * 100
        drops_intraday = df[df['change_intraday'] <= -min_drop].copy()
        drops_intraday['tipo'] = 'Intraday'
        drops_intraday['change_close'] = drops_intraday['change_intraday']
        
        # Combinar todos os tipos e remover duplicatas por data
        all_drops = pd.concat([drops_close, drops_drawdown, drops_intraday])
        
        # Agrupar por data e pegar a maior queda
        if len(all_drops) > 0:
            all_drops = all_drops.sort_values('change_close').groupby('date').first().reset_index()
        
        print(f"üîç Encontradas {len(all_drops)} quedas de {min_drop}%+ (usando m√∫ltiplos m√©todos)")
        if len(all_drops) > 0:
            print(f"   - Close-to-Close: {len(drops_close)}")
            print(f"   - Peak-to-Valley: {len(drops_drawdown)}")
            print(f"   - Intraday: {len(drops_intraday)}")
        
        return all_drops
    
    def analyze_recovery(self, df: pd.DataFrame, drops: pd.DataFrame, days_ahead: int = 7) -> List[Dict]:
        """Analisa recupera√ß√£o ap√≥s quedas"""
        results = []
        
        for idx, drop_row in drops.iterrows():
            drop_date = drop_row['date']
            drop_price = drop_row['close']
            drop_change = drop_row['change_close']
            drop_tipo = drop_row.get('tipo', 'Unknown')
            
            # Pegar dias seguintes
            future_data = df[df['date'] > drop_date].head(days_ahead)
            
            if len(future_data) == 0:
                continue
            
            # Encontrar recupera√ß√£o
            recovery_day = None
            recovery_price = None
            max_gain = 0
            max_gain_day = None
            
            for future_idx, future_row in future_data.iterrows():
                days_passed = (future_row['date'] - drop_date).days
                current_price = future_row['close']
                gain = ((current_price - drop_price) / drop_price) * 100
                
                if recovery_day is None and current_price > drop_price:
                    recovery_day = days_passed
                    recovery_price = current_price
                
                if gain > max_gain:
                    max_gain = gain
                    max_gain_day = days_passed
            
            results.append({
                'date': drop_date,
                'tipo': drop_tipo,
                'drop_percent': drop_change,
                'drop_price': drop_price,
                'recovery_days': recovery_day,
                'recovery_price': recovery_price,
                'max_gain_percent': max_gain,
                'max_gain_days': max_gain_day,
                'recovered': recovery_day is not None
            })
        
        return results
    
    def print_statistics(self, results: List[Dict]):
        """Imprime estat√≠sticas melhoradas"""
        if len(results) == 0:
            print("‚ùå Nenhuma queda encontrada no per√≠odo")
            return
        
        df_results = pd.DataFrame(results)
        df_complete = df_results[df_results['max_gain_days'].notna()]
        
        print("="*80)
        print("üìä ESTAT√çSTICAS DA ESTRAT√âGIA 'BUY THE DIP'")
        print("="*80)
        
        print(f"\nüìâ QUEDAS ANALISADAS:")
        print(f"   Total de quedas: {len(df_results)}")
        print(f"   Queda m√©dia: {df_results['drop_percent'].mean():.2f}%")
        print(f"   Maior queda: {df_results['drop_percent'].min():.2f}%")
        
        # Por tipo
        if 'tipo' in df_results.columns:
            print(f"\nüìä QUEDAS POR TIPO:")
            for tipo in df_results['tipo'].unique():
                count = len(df_results[df_results['tipo'] == tipo])
                print(f"   {tipo}: {count}")
        
        print(f"\nüìà RECUPERA√á√ÉO:")
        recovered = df_results['recovered'].sum()
        recovery_rate = (recovered / len(df_results)) * 100
        print(f"   Taxa de recupera√ß√£o: {recovery_rate:.1f}% ({recovered}/{len(df_results)})")
        
        if recovered > 0:
            df_recovered = df_results[df_results['recovered'] == True]
            print(f"   Tempo m√©dio: {df_recovered['recovery_days'].mean():.1f} dias")
            print(f"   Mais r√°pida: {df_recovered['recovery_days'].min():.0f} dias")
            print(f"   Mais lenta: {df_recovered['recovery_days'].max():.0f} dias")
        
        if len(df_complete) > 0:
            print(f"\nüí∞ GANHOS POTENCIAIS (7 dias ap√≥s):")
            print(f"   Ganho m√©dio: {df_complete['max_gain_percent'].mean():.2f}%")
            print(f"   Maior ganho: {df_complete['max_gain_percent'].max():.2f}%")
            print(f"   Menor: {df_complete['max_gain_percent'].min():.2f}%")
            
            # Win rate por thresholds
            for threshold in [1.0, 2.0, 3.0]:
                winning = (df_complete['max_gain_percent'] >= threshold).sum()
                win_rate = (winning / len(df_complete)) * 100
                print(f"\nüéØ WIN RATE (lucro ‚â•{threshold}%):")
                print(f"   {win_rate:.1f}% ({winning}/{len(df_complete)})")
        
        print("\n" + "="*80)
        
        return df_results
    
    def print_recent_opportunities(self, results: List[Dict], n: int = 10):
        """Mostra √∫ltimas oportunidades"""
        if len(results) == 0:
            return
            
        print(f"\nüìÖ √öLTIMAS {min(n, len(results))} QUEDAS DETECTADAS:")
        print("="*80)
        
        df_results = pd.DataFrame(results)
        recent = df_results.tail(n)
        
        for idx, row in recent.iterrows():
            print(f"\nüìÖ {row['date']} [{row.get('tipo', 'N/A')}]")
            print(f"   üí∏ Pre√ßo: R$ {row['drop_price']:,.2f}")
            print(f"   üìâ Queda: {row['drop_percent']:.2f}%")
            
            if row['recovered']:
                print(f"   ‚úÖ Recuperou em {row['recovery_days']:.0f} dias")
            
            if pd.notna(row['max_gain_percent']):
                print(f"   üìà Ganho m√°x: {row['max_gain_percent']:.2f}% em {row['max_gain_days']:.0f} dias")
        
        print("\n" + "="*80)
    
    def run_analysis(self, days: int = 180, min_drop: float = 5.0):
        """Executa an√°lise completa"""
        print("\nüöÄ INICIANDO AN√ÅLISE HIST√ìRICA MELHORADA\n")
        
        df = self.get_historical_data(days)
        
        if df is None or len(df) == 0:
            print("\n‚ùå N√£o foi poss√≠vel obter dados")
            print("üí° Poss√≠veis causas:")
            print("   - API da Binance temporariamente indispon√≠vel")
            print("   - Limite de requisi√ß√µes atingido")
            print("   - Problemas de conex√£o")
            print("\nüîß Solu√ß√µes:")
            print("   - Aguarde alguns minutos e tente novamente")
            print("   - Verifique sua conex√£o com internet")
            print("   - Tente diminuir o per√≠odo de an√°lise")
            return None, None
        
        # Encontrar quedas (m√©todo melhorado)
        drops = self.find_drops_advanced(df, min_drop)
        
        if len(drops) == 0:
            print(f"\nüí° DICA: Nenhuma queda de {min_drop}%+ detectada.")
            print(f"   Tente diminuir o threshold (ex: 3% ou 4%) para ver mais oportunidades.")
            return df, None
        
        # Analisar recupera√ß√£o
        print(f"\n‚è≥ Analisando recupera√ß√£o das quedas...\n")
        results = self.analyze_recovery(df, drops)
        
        # Estat√≠sticas
        df_results = self.print_statistics(results)
        
        # √öltimas oportunidades
        self.print_recent_opportunities(results)
        
        return df, df_results

def main():
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë      üìä AN√ÅLISE HIST√ìRICA BTC/BRL - VERS√ÉO MELHORADA      ‚ïë
    ‚ïë              M√∫ltiplos M√©todos de Detec√ß√£o                ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    analyzer = ImprovedBacktestAnalyzer()
    
    # Tentar com 5%, se n√£o achar nada, tentar com 3%
    df, results = analyzer.run_analysis(days=180, min_drop=5.0)
    
    if results is None and df is not None:
        print("\nüîÑ Tentando novamente com threshold de 3%...")
        drops = analyzer.find_drops_advanced(df, min_drop=3.0)
        if len(drops) > 0:
            results_list = analyzer.analyze_recovery(df, drops)
            analyzer.print_statistics(results_list)
            analyzer.print_recent_opportunities(results_list)
    
    if df is not None:
        print("\n‚úÖ An√°lise conclu√≠da!")
        print("üí° Use essas estat√≠sticas para ajustar config.py")

if __name__ == "__main__":
    main()
